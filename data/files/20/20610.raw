function cg_negate!(A::Array)
    for i in 1:length(A)
        A[i] = -A[i]
    end
end

# Preconditioners
# Empty preconditioner
cg_precondfwd(out::Array, P::Nothing, A::Array) = copy!(out, A)
cg_precondfwddot(A::Array, P::Nothing, B::Array) = dot(A, B)
cg_precondinvdot(A::Array, P::Nothing, B::Array) = dot(A, B)

# Diagonal preconditioner
function cg_precondfwd(out::Array, p::Vector, A::Array)
    for i in 1:length(A)
        out[i] = p[i] * A[i]
    end
    return out
end
function cg_precondfwddot(A::Array, p::Vector, B::Array)
    s = zero(eltype(A))
    for i in 1:length(A)
        s += A[i] * p[i] * B[i]
    end
    return s
end
function cg_precondinvdot(A::Array, p::Vector, B::Array)
    s = zero(eltype(A))
    for i in 1:length(A)
        s += A[i] * B[i] / p[i]
    end
    return s
end

#
# Conjugate gradient
#
# Syntax:
#    x, fval, f_calls, converged = cgdescent(func, x0)
#    x, fval, f_calls, converged = cgdescent(func, x0, options)
#
# Inputs:
#   x0 must be an array, but does not have to be a vector (this is useful
#     if the shape is meaningful to your objective function).
#
#   func must have syntax
#      val = func(g, x)
#
#   where g is storage for the gradient (or nothing, if the
#   gradient is not desired)
#
# Outputs:
#   x is the final setting of your input guess
#
#   fval is a vector of function values, one per linesearch (the first
#     is the initial function value)
#
#   f_calls is the number of function evaluations
#
#   converged is true if the algorithm converged to the prescibed
#     tolerance, and false if it terminated due to an excessive number
#     of iterations.
#
# This is an independent implementation of:
#   W. W. Hager and H. Zhang (2006) Algorithm 851: CG_DESCENT, a
#     conjugate gradient method with guaranteed descent. ACM
#     Transactions on Mathematical Software 32: 113â€“137.
#
# Code comments such as "HZ, stage X" or "HZ, eqs Y" are with
# reference to a particular point in this paper.
#
# Several aspects of the following have also been incorporated:
#   W. W. Hager and H. Zhang (2012) The limited memory conjugate
#     gradient method.
#
# This paper will be denoted HZ2012 below.
#
# It's worth noting that, in addition to the modified update rule that
# guarantees descent, one of the attractions of this paper is its
# high-quality (and somewhat complex) line search algorithm.
# Naturally, can be used with other minimization routines, and indeed
# a related H&Z paper showed that it can speed the convergence of
# L-BFGS.
#
# There are some modifications and/or extensions from what's in the
# paper (these may or may not be extensions of the cg_descent code
# that can be downloaded from Hager's site; his code has undergone
# numerous revisions since publication of the paper):
#
#   cgdescent: the termination condition employs a "unit-correct"
#     expression rather than a condition on gradient
#     components---whether this is a good or bad idea will require
#     additional experience, but preliminary evidence seems to suggest
#     that it makes "reasonable" choices over a wider range of problem
#     types.
#
#   linesearch: the Wolfe conditions are checked only after alpha is
#     generated either by quadratic interpolation or secant
#     interpolation, not when alpha is generated by bisection or
#     expansion. This increases the likelihood that alpha will be a
#     good approximation of the minimum.
#
#   linesearch: In step I2, we multiply by psi2 only if the convexity
#     test failed, not if the function-value test failed. This
#     prevents one from going uphill further when you already know
#     you're already higher than the point at alpha=0.
#
#   both: checks for Inf/NaN function values
#
#   both: support maximum value of alpha (equivalently, c). This
#     facilitates using these routines for constrained minimization
#     when you can calculate the distance along the path to the
#     disallowed region. (When you can't easily calculate that
#     distance, it can still be handled by returning Inf/NaN for
#     exterior points. It's just more efficient if you know the
#     maximum, because you don't have to test values that won't
#     work.) The maximum should be specified as the largest value for
#     which a finite value will be returned.  See, e.g., limits_box
#     below.  The default value for alphamax is Inf. See alphamaxfunc
#     for cgdescent and alphamax for linesearch_hz.

function cg_trace!(tr::OptimizationTrace,
                   x::Vector,
                   f_x::Real,
                   gr::Vector,
                   alpha::Real,
                   iteration::Integer,
                   store_trace::Bool,
                   show_trace::Bool)
    dt = Dict()
    dt["g(x)"] = copy(gr)
    dt["Current step size"] = alpha
    dt["Maximum component of g(x)"] = norm(gr, Inf)
    os = OptimizationState(copy(x), f_x, iteration, dt)
    if store_trace
        push!(tr, os)
    end
    if show_trace
        println(os)
    end
end

function cg{T}(df::Union(DifferentiableFunction,
                         TwiceDifferentiableFunction),
               initial_x::Array{T};
               tolerance::Real = eps(T)^(2/3),
               iterations::Integer = 1_000,
               store_trace::Bool = false,
               show_trace::Bool = false,
               linesearch!::Function = hz_linesearch!,
               eta::Real = 0.4,
               display::Integer = 0,
               alpha::Real = nan(T),
               fcountmax::Integer = typemax(Int),
               nfailuresmax::Integer = 1_000,
               iterfinitemax::Integer = 20,
               P::Any = nothing,
               precondprep::Function = (P, x) -> nothing)

    # Maintain current state in x
    x = copy(initial_x)

    # Count the total number of iterations
    iteration = 0

    # Track calls to function and gradient
    f_calls = 0
    g_calls = 0

    # Count number of parameters
    N = length(x)

    # Maintain current gradient in gr and previous gradient in gr_previous
    gr = similar(x)
    gr_previous = similar(x)

    # Maintain the preconditioned gradient in pgr
    pgr = similar(x)

    # The current search direction
    s = similar(x)

    # Buffers for use in line search
    x_ls = similar(x)
    gr_ls = similar(x)

    # Intermediate value in CG calculation
    y = similar(x)

    # Store f(x) in f_x
    f_x = df.fg!(x, gr)
    f_calls += 1
    g_calls += 1
    copy!(gr_previous, gr)

    # Store history of function values in fval
    fval = [f_x]

    # Keep track of step-sizes
    alpha = alphainit(1.0, x, gr, f_x)

    # TODO: How should this flag be set?
    mayterminate = false

    # Maintain a cache for line search results
    lsr = LineSearchResults(T)

    # Trace the history of states visited
    tr = OptimizationTrace()
    tracing = store_trace || show_trace
    if tracing
        cg_trace!(tr, x, f_x, gr, alpha,
                  iteration, store_trace, show_trace)
    end

    # Output messages
    if !isfinite(f_x)
        error("Must have finite starting value")
    end

    if !all(isfinite(gr))
        @show gr
        @show find(!isfinite(gr))
        error("Gradient must have all finite values at starting point")
    end

    if display & ITER > 0
        @printf("Iter     Evals    Function value   |step|\n")
        @printf("------   ------   --------------   --------------\n")
        @printf("%6d   %6d   %14e\n", iteration, f_calls, f_x)
    end

    # First iteration store the preconditioned gradient in s
    precondprep(P, x)
    cg_precondfwd(s, P, gr)

    # s -> -s
    cg_negate!(s)

    phi0 = f_x         # value at alpha = 0
    dphi0 = dot(gr, s) # derivative at alpha = 0
    @assert dphi0 < 0

    push!(lsr, zero(T), phi0, dphi0)

    absstep = zero(T)

    # Iterate until convergence
    converged = false
    while !converged && iteration <= iterations
        # Increment the number of steps we've had to perform
        iteration += 1

        # Save the previous value
        f_x_old = f_x

        # TODO: Restore
        # # Refresh the line search cache
        # dphi0 = dot(gr, s)
        # clear!(lsr)
        # push!(lsr, zero(T), f_x, dphi0)

        # Messages
        if display & PARAMETERS > 0
            println("x: ", x)
        end
        if display & GRADIENT > 0
            println("gradient:   ", gr)
        end
        if display & SEARCHDIR > 0
            println("search:     ", s)
        end

        # Determine the distance of movement along the search line
        alpha, f_update, g_update =
          linesearch!(df, x, s, x_ls, gr_ls, lsr, alpha, mayterminate)
        f_calls += f_update
        g_calls += g_update

        @assert isfinite(f_x)

        if display & ALPHA > 0
            println("alpha: ", alpha)
        end

        # Update current position
        for i in 1:N
            x[i] = x[i] + alpha * s[i]
        end

        # Can this be here?
        # # Maintain a record of the previous gradient
        # copy!(gr_previous, gr)

        # Update the function value and gradient
        f_x = df.fg!(x, gr)
        f_calls += 1
        g_calls += 1

        # Assess convergence
        # TODO: Find a way to move this later and avoid break's
        if norm(gr, Inf) < tolerance
            converged = true
            break
        end

        # Test for termination (this differs from HZ eq 30; at least
        # here, it seems to make sense to be "unit-correct", i.e., to
        # make the criterion respect the possibility that different
        # parameters have different scaling/physical units)

        # has units of the function value
        absstep = alpha * sum(abs(gr .* s))
        fsum = abs(f_x) + abs(f_x_old)
        if absstep <= tolerance * fsum / N ||
              abs(f_x) < eps(max(max(abs(x)), max(abs(gr))))
            converged = true
            break
        end

        if iteration > iterations || f_calls > fcountmax ||
              lsr.nfailures > nfailuresmax
            break
        end

        # Determine the next search direction using HZ's CG rule

        # Calculate the beta factor (HZ2012)
        precondprep(P, x)
        dPd = cg_precondinvdot(s, P, s)
        etak::T = eta * dot(s, gr_previous) / dPd

        for i = 1:N
            y[i] = gr[i] - gr_previous[i]
        end

        copy!(gr_previous, gr)

        ydotd = dot(y, s)

        cg_precondfwd(pgr, P, gr)

        betak = (dot(y, pgr) - cg_precondfwddot(y, P, y) * dot(s, gr) / ydotd) / ydotd

        beta = max(betak, etak)

        # Generate the new search direction
        for i = 1:N
            s[i] = beta * s[i] - pgr[i]
        end

        phi0 = f_x             # value at alpha = 0
        dphi0 = dot(gr, s)     # derivative at alpha = 0
        if dphi0 >= 0
            for i = 1:N
                s[i] = -gr[i]       # reset
            end
            dphi0 = dot(gr, s)      # derivative at alpha = 0
            if dphi0 >= 0
                println(s)
                println(gr)
                println(dphi0)
            end
            @assert dphi0 < 0
        end

        # Clear the line search results
        clear!(lsr)
        push!(lsr, zero(T), phi0, dphi0)

        # Pick the initial step size (HZ #I1-I2)
        alpha, mayterminate, f_up, g_up =
          alphatry(alpha, df, x, s, x_ls, gr_ls, lsr)
        f_calls += f_up
        g_calls += g_up

        if tracing
            cg_trace!(tr, x, f_x, gr, alpha,
                      iteration, store_trace, show_trace)
        end
    end

    OptimizationResults("Conjugate Gradient",
                        initial_x,
                        x,
                        f_x,
                        iteration,
                        converged,
                        tr,
                        f_calls,
                        g_calls)
end
