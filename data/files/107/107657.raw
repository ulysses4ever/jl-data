#Caterpillar Tube Pricing Benchmark
#Julia Ver. 0.0.4 # data merged

#Install Needed Libraries
#Pkg.add("BinDeps")
#Pkg.add("JSON")
#Pkg.add("DataFrames")
#Pkg.add("Gadfly")
#Pkg.add("XGBoost")

#Libraries, directories, options and extra functions----------------------
Pkg.update()

using JSON
using DataFrames
using Dates
using Gadfly
using XGBoost

#Read Settings file
cd(dirname(@__FILE__()))
directories = JSON.parsefile("SETTINGS.json")

dataDirectory = directories["dataDirectory"]
edaDirectory = directories["EDALoc"]

#Load data
train = readtable(dataDirectory * "train_set.csv")
test = readtable(dataDirectory * "test_set.csv")
test = test[:, 2:size(test, 2)]
test[:cost] = 0
train[:idx] = -[1:size(train, 1)]
test[:idx] = [1:size(test, 1)]
dataFull = vcat(train, test)

#Data Transformations
#Quote Dates to numeric columns
dataFull[:quote_date] = Date(dataFull[:quote_date], "y-m-d")

#New Columns
dataFull[:year] = year(dataFull[:quote_date])
dataFull[:month] = month(dataFull[:quote_date])
dataFull[:day] = day(dataFull[:quote_date])
dataFull[:dayWeek] = dayofweek(dataFull[:quote_date])

#Merge all dataframes
dataFull = join(dataFull, readtable(dataDirectory * "bill_of_materials.csv"),
                on = :tube_assembly_id, kind = :inner)
dataFull = join(dataFull, readtable(dataDirectory * "specs.csv"),
                on = :tube_assembly_id, kind = :inner)
dataFull = join(dataFull, readtable(dataDirectory * "tube.csv"),
                on = :tube_assembly_id, kind = :inner)

namesAndTypes = hcat(names(dataFull), eltypes(dataFull))

#Categorical Columns to Frequency
function categorical2frequency(dataVector)
  #This functions counts the occurences of a category and maps it back to the data provided
  #countmap is similar to the function "table()" in R, the only difference is that countmap() returns a dictionary
  vectorDict = countmap(dataVector)
  newVector = [vectorDict[dataPoint] for dataPoint in dataVector]
  return newVector
end

categoricalColumns = [:bracket_pricing, :supplier, :component_id_1, :component_id_2, :component_id_3, :component_id_4,
                      :component_id_5, :component_id_6, :component_id_7, :component_id_8, :spec1,
                      :spec2, :spec3, :spec4, :spec5, :spec6, :spec7, :spec8, :spec9, :spec10, :material_id,
                      :end_a_1x, :end_a_2x, :end_x_1x, :end_x_2x, :end_a, :end_x]

for singleCol in categoricalColumns
  dataFull[singleCol] = categorical2frequency(dataFull[singleCol])
end

#Remove NAs from data
validColumns = [:annual_usage, :bracket_pricing, :min_order_quantity, :quantity,
                :year, :month, :day, :dayWeek, :supplier, :quantity_1, :quantity_2,
                :quantity_3, :quantity_4, :quantity_5, :quantity_6, :quantity_7, :quantity_8,
                :diameter, :wall, :length, :num_bends, :bend_radius, :num_boss, :num_bracket, :other]

for singleCol in validColumns
  dataFull[isna(dataFull[singleCol]) .== true, singleCol] = -999
end

#Remap the data to the original partitions
train = dataFull[dataFull[:idx].< 0, :]
test = dataFull[dataFull[:idx].> 0, :]

#Shuffle train DataFrame
shuffledIdxs = shuffle([1:size(train, 1)])
train = train[shuffledIdxs, :]

#EDA (Example)
#This section contains a few simple examples; if you want to learn more about Gadfly, check out
#http://www.gadflyjl.org/

#EDA 1; Cost Histograms
#Cost histogram
plot(train, x = "cost", Geom.histogram,
     Guide.ylabel("Amount"), Guide.xlabel("Cost"))
#Log Cost histogram; useful for linear models and posible outlier detection
plot(train, x = "cost", Geom.histogram, Scale.x_log,
     Guide.ylabel("Amount"), Guide.xlabel("Cost in Log Scale"))

#EDA #2; tube cost vs. volume order
#This plot was based on the script found on:
#https://www.kaggle.com/timabram/caterpillar-tube-pricing/tube-pricing-data-exploration-v2
plot(train, x = "quantity", y = "cost", Geom.histogram, Geom.point, Scale.x_log, Scale.y_log,
     Geom.smooth(method = :loess, smoothing = 0.9), Guide.xlabel("Quantity Bought in Log Scale"), Guide.ylabel("Cost in Log Scale"))

#Transform DataFrame into Array{float32} (which is currently supported by xgboost in julia)
costTraining = convert(Array{Float32}, train[:, :cost])
costTrainingLog = log1p(convert(Array{Float32}, train[:, :cost]))
trainArray = convert(Array{Float32}, train[:, vcat(categoricalColumns, validColumns)])
testArray = convert(Array{Float32}, test[:, vcat(categoricalColumns, validColumns)])

#XGBOOST
#Create Binary Matrices
dtrain = DMatrix(trainArray, label = costTrainingLog)
dtest = DMatrix(testArray)

#Define the evaluation function (xgboost currently doesn't support RMSLE)
function evalRMSLE(preds::Array{Float32, 1}, dtrain::DMatrix)
  labels = get_info(dtrain, "label")
  # return a pair metric_name, result
  differenceLogs = log(1 + preds) - log(1 + labels)
  RMSLEError = sqrt(1/length(differenceLogs) * sum([x ^ 2 for x in differenceLogs]))
  return ("RMSLE", RMSLEError)
end

#5fold Cross-Validation
nfold = 5
num_round = 1000
param = ["max_depth" => 10, "objective" => "reg:linear", "silent" => 1]

#nfold_cv(dtrain, num_round, nfold, param = param, seed = 0)  #This takes too long, the evaluation function has to be further optimized

#Model Training
#with RMSLE Evaluation
#XGBoostModel = xgboost(dtrain, num_round, param = param, feval = evalRMSLE)
#without RMSLE Evaluation
XGBoostModel = xgboost(dtrain, num_round, param = param)

#Model Evaluation
dump_model(XGBoostModel, "dump.nice.txt")

#Predictions using test data
preds = exp(predict(XGBoostModel, dtest)) - 1

#Write Results
sampleSubmission = readtable(dataDirectory * "sample_submission.csv")
sampleSubmission[:cost] = preds

writetable("juliaXGBoostI.csv", sampleSubmission)

