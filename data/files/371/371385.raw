# Elio liquido dentro un confinamento armonico, con VMC. Il resto del modulo sono funioni generali che poi si applicano a quella cosa
module mc
srand(10)
import Roots
using Debug
# un iteratore è un qualsiasi tipo che abbia definiti i metodi start, next e done

# Un iteratore che campiona usando metropolis. Lo si inizializza con la distribuzione da campionare e lui produce uno alla volta i campioni
# si potrebbe aggiungere un campo per la lunghezza di correlazione così dico a next di tirare fuori solo punti scorrelati
type MarkovChain{T}
    value::T
    delta::Float64
    p::Function
    accepted::Int # ci mettiamo anche un campo che conta quelli proposti?
    steps::Int
    prop::T
end

function Base.display(chain::MarkovChain)
    println("Datatype:\t$(typeof(chain.value))")
    println("Delta:   \t$(chain.delta)")
    println("Distrib: \t$(chain.p)")
    println("Accepted:\t$(chain.accepted)")
    println("Length:  \t$(chain.steps)")
    println("Ratio:   \t$(chain.accepted/chain.steps)")
end

# Un costruttore comodo con dei valori di default sensati
MarkovChain(;init=0.0, delta=1.0, p=gauss, steps=100000) = MarkovChain{typeof(init)}(init, delta, p, 0, steps, deepcopy(init))

# state inizia da 1 ed è un intero, conta quanta roba ho prodotto
Base.start(chain::MarkovChain) = 1

# next deve restituire il valore dell'iteratore ed il prossimo stato (che è un intero)
function Base.next(chain::MarkovChain{Float64}, state::Int)
    proposal = chain.value + chain.delta*(rand() - 0.5)
    w        = chain.p(proposal)/chain.p(chain.value)
    if w >= 1 || w > rand() # se è più probabile starci lo accetto, altrimenti uniforme
        chain.accepted += 1
        chain.value = proposal
    else # se ho rifutato rimango dove sono
        chain.value = chain.value
    end
    return chain.value, state+1
end

# metodo per gestire configurazioni a molte particelle
function Base.next{T<:Array}(chain::MarkovChain{T}, state::Int)
    # la configurazione va generata tutta insieme, non una particella alla volta
    for i in 1:length(chain.value)
        rand!(chain.prop[i])
        for j in 1:length(chain.prop[i])
            chain.prop[i][j] = chain.value[i][j] + chain.delta*(chain.prop[i][j] - 0.5) 
        end
    end
    w = chain.p(chain.prop)/chain.p(chain.value)
    if w >= 1 || w > rand() # se è più probabile starci lo accetto, altrimenti uniforme
        chain.accepted += 1
        for i in 1:length(chain.value)
            for j in 1:length(chain.value[i])
                chain.value[i][j] = chain.prop[i][j] 
            end
        end
        #= chain.value = deepcopy(chain.prop) # è lento FIXME =#
    else # se ho rifutato rimango dove sono
        chain.value = chain.value
    end
    return chain.value, state+1
end

# definendo questo metodo posso fare le comprehensions
Base.length(chain::MarkovChain) = chain.steps

# in questo modo i cicli sono 'for val in catena' e sanno quando fermarsi  
Base.done(chain::MarkovChain, state) = state > chain.steps

function burn!(chain::MarkovChain, num::Int)
    # fa girare a vuoto chain per num passi
    for i in 1:num
        next(chain, num)
        print("\rburning in... $i/$num")
    end
    println("")
    chain.accepted = 0
end

function gauss(x)
    # variabile gaussiana standard, è il default per MarkovChain.p
    return exp(-dot(x,x)/2)
end

function gauss{T<:Array}(x::T)
    return exp(-sum(map(y->dot(y,y), x)))
end

function NR(f, x, dx, h; verbose=false)
    # così controlla la qualità dello zero e non la precisione
    count = 1
    x0 = x
    x_old = x + 1
    x_new = x
    while abs(x_new-x_old) > dx
        x_old = x_new
        x_new = x_old - 2h*f(x_old)/(f(x_old+h)-f(x_old-h))
        if verbose
            println(x, "\t",abs(f(x)))
        else
            write(".")
        end
        count += 1
        if count > 15
            warn("Non è stata raggiunta la convergenza in 15 iterazioni, restituisco la stima iniziale")
            return x0
        end
    end
    return x_new
end

function regola_acc_rate!(target_rate::Float64, catena::MarkovChain)
    # aggiusta delta in place finché accepted/steps non fa target_rate
    old_steps = catena.steps
    function acceptance_rate(delta::Float64)
        catena.accepted = 0
        catena.steps = 10000
        catena.delta = delta
        for val in catena # è vuoto perchè deve solo produrre i valori e non farci niente
        end
        return catena.accepted/catena.steps - target_rate
    end
    print("Regolo delta:")
    catena.delta    = NR(acceptance_rate, catena.delta, 0.01, 1e-2, verbose=false)
    catena.accepted = 0
    catena.steps    = old_steps
    println(catena.delta)
    return catena.delta
end

function monte_carlo(stimatori, catena::MarkovChain)
    # gli passo un dizionario di funzioni da integrare con la catena e lui restituisce
    # un dizionario di risultati numerici con le stesse chiavi
    integrali = [nome => 0.0 for nome in keys(stimatori)]
    count = 0
    for val in catena
        count += 1
        i = div(count, div(catena.steps,50))
        # si può mettere in una funzione a parte progressbar(partial, total)
        print("\rIntegrazione: $count/$(catena.steps) [","*"^i," "^(50-i),"] $(2*i)%")
        for (nome,funzione) in stimatori
            integrali[nome] += funzione(val)
        end
    end
    print("\n")
    for (nome,somma) in integrali
        integrali[nome] = somma/catena.steps
    end
    return integrali 
end

function gradiente(f, p, a, da, catena)
    # fa il gradiente con il ripesamento del funzionale ∫f⋅p valutato in a±da
    #= return (E(a+da) - E(a-da))/2da =#
    fd(x)    = f(x,a+da)*p(x,a+da)/p(x,a)
    wd(x)    = p(x,a+da)/p(x,a)
    fs(x)    = f(x, a+da)*p(x,a-da)/p(x,a)
    ws(x)    = p(x,a-da)/p(x,a)
    stimatori = ["Peso a-da"=>ws, "Peso a+da"=>wd, "Integr. a+da"=>fd, "Integr. a-da"=>fs]
    res =  monte_carlo(stimatori, catena)
    return (res["Integr. a+da"]/res["Peso a+da"] - res["Integr. a-da"]/res["Peso a-da"])/2da  
end

function sq(x)
    # gli dai un array di 3vettori e lui fa ∑rᵢ²
    sum::Float64 = 0.0
    for i in 1:length(x)
        for j in 1:length(x[i])
            sum += x[i][j]*x[i][j]
        end
    end
    return sum
end

function en_kin(x,a=a,b=b)
    # usando jackson feenberg
    u(r)   = (b/r)^5
    du(r)  = -5*b^5/r^6
    d2u(r) = 30*b^5/r^7
    en::Float64 = 3*particles/(2*a) 
    for l in 1:length(x)
        for i in 1:l-1 
            dist = 0.0
            for j in 1:length(x[i])
                dist += (x[i][j] - x[l][j])^2
            end
            dist   = sqrt(dist)
            en    += -1/2*d2u(dist) - du(dist)/dist # come dice il tipo della tesi
        end
    end
    return -zkin*en
end

gradu = zeros(3) # forse va bene anche allocarlo dentro en_kin
function en_kin_std(x,a=a,b=b)
    u(r)   = (b/r)^5
    du(r)  = -5*b^5/r^6
    d2u(r) = 30*b^5/r^7
    en::Float64 = 0.0
    for l in 1:length(x)
        en += (dot(x[l],x[l]) - 3*a)/a^2 
        for i in 1:l-1 
            dist = 0.0
            for j in 1:length(x[i])
                dist += (x[i][j] - x[l][j])^2
            end
            dist   = sqrt(dist)
            dusur  = du(dist)/dist
            en    += -d2u(dist)-2*dusur
            for j in 1:length(x[i])
                gradu[j] += dusur*(x[i][j]-x[l][j]) # poi fare al quadrato e sommare ad en
            end
        end
        en += dot(gradu, gradu)
        en += 2*dot(x[l], gradu)/a 
    end
    for j in 1:3
        gradu[j] = 0.0
    end
    return -zkin*en
end

function en_pot(x)
    en::Float64 = zho*sq(x) # oscillatore armonico
    for i in 1:length(x)
        for l in 1:i-1
            r2 = 0.0
            for j in 1:length(x[i])
                r2 += (x[i][j] - x[l][j])^2
            end
            en += 4*ep*(r2^(-6)-r2^(-3)) # lennard jones
        end
    end
    return en
end

# Orbitale gaussiano
psi(x,a) = exp(-sq(x)/a)
psi(x)   = psi(x,a)

# Jastrow
function phi(x,b)
    jas = 1.0
    for i in 1:length(x)
        for l in 1:i-1
            r = 0.0
            for j in 1:length(x[i])
                r += (x[i][j] - x[l][j])^2
            end
            r = sqrt(r)
            jas *= exp(-(b/r)^5)
        end
    end
    return jas
end
phi(x) = phi(x,b)

##################################################
# particelle interagenti LJ in una buca armonica #
# le unità sono E = Kb, L = σ                    # 
##################################################

# le funzioni che dipendono da un parametro hanno due metodi: uno che prende il parametro come secondo argomento ed uno che usa il valore globale del parametro

hbar    = 1.0546e-34   # J s
kb      = 1.380649e-23 # J/K
mass    = 6.6465e-27   # kg
sigma   = 2.556e-10    # m
ep      = 10.22        # K

# Mi aspetto una fase ordinata ed una disordinata, a questa densità dovrebbe essere disordinato e liquido
dens      = 2.2e28 # 2.2e28 atomi/m³ è il valore dell'elio liquido all'equilibrio 
particles = 13 # 13,24,29,34,37 sono massimi locali di stabilità per LJ 

omega = hbar/mass * (4/3 * pi * dens/particles)^(2/3) # 1/s
aho   = sqrt(hbar/(mass*omega))/sigma                 # m
eho   = hbar*omega/(2*kb)                             # J

zkin = hbar^2/(2*mass*kb*sigma^2)  # K
zho  = mass*omega^2*sigma^2/(2*kb) # K

println("Omega = $omega 1/s")
println("\nEho  = $eho K")
println("aho  = $aho σ\n")
println("ζkin = $zkin K")
println("ζho  = $zho K\n")
#= exit(0) =#

a = 1.0  # più o meno la larghezza di oscillatore armonico
b = 1.4   # deve essere più o meno la larghezza del core delle particelle
p(x) = psi(x)*phi(x)

stimatori = ["En. cinetica"=>en_kin, "En.Potenziale"=>en_pot]

# La configurazione è una tupla di array lunghi 3
x = [zeros(3) for i in 1:particles]
catena = MarkovChain(init = [randn(3) for i in 1:particles], steps=30000, p=p, delta=0.3)
# almeno 2e4 di burn in, bisogna dargli tempo di condensare nel close packing

#= burn!(catena, 20000) =#
#= regola_acc_rate!(0.5, catena) =#
#= risultati = monte_carlo(stimatori, catena) =#
#= display(catena) =#
#= display(risultati) =#
#= print("\n   E = $(sum(values(risultati))) K\n")  =#

function E(a)
    p(x)      = psi(x,a)*phi(x)
    en_loc(x) = en_kin(x,a)+en_pot(x)
    stimatori = ["En. locale"=>en_loc]
    catena    = MarkovChain(init = [randn(3) for i in 1:particles], steps=300000, p=p, delta=0.2)
    burn!(catena, 20000)
    regola_acc_rate!(0.5, catena)
    println("a = $(round(a,3))\tdelta = $(round(catena.delta, 2))")
    return  monte_carlo(stimatori, catena)["En. locale"]
end
# calcolo le energie per alcuni valori del parametro, per farmi un'idea di dove sta il minimo
as      = linspace(0.5, 3.0, 64)
energie = Float64[]
for a in as
    en = E(a)
    push!(energie, en)
end
using PyPlot
plot(as, energie, linestyle="-", marker="")


#= function minimizza_energia_braveness(a_iniz, braveness, da, tolerance) =#
#=     # per l'oscillatore armonico 3d =#
#=     a = a_iniz =#
#=     while true =#
#=         en_loc(x,a) = en_kin(x,a)+en_pot(x) =#
#=         p(x)    = psi(x,a)*phi(x) =#
#=         catena = markovchain(init=[randn(3) for i in 1:particles], steps=100000, p=p, delta=0.3) =#
#=         regola_acc_rate!(0.5, catena) =#
#=         burn!(catena, 20000) =#
#=         grad        = gradiente(en_loc, p, a, da, catena) =#
#=         print("\r a = $(round(a, 5)) \t grad = $(round(grad, 5))") =#
#=         if norm(grad)<tolerance =#
#=             break =#
#=         else =#
#=             a = a - grad*braveness =#
#=             println(" --> \ta_new = $(round(a, 5))") =#
#=         end =#
#=     end =#
#=     println("") =#
#=     return a =#
#= end =#

#= minimizza_energia_braveness(0.9, 0.02, 1e-6, 1e-3) =#

end # fine modulo








