#
# LNNA: Living Neural Network Analyzer 
# Copyright (C) 2015  Jimmy Dubuisson <jimmy.dubuisson@gmail.com>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#

using Logging


@Logging.configure(level=DEBUG)

function get_H_entry(s::Int64,t::Int64,alphas::Array{Float64,1},betas::Array{Float64,2},gammas::Array{Float64,2})
	n = length(alphas)
	s_digits = digits(s,2,n)
	t_digits = digits(t,2,n)

	q = float64(0)
	# @debug(s,":",t)

	for i in 1:n
		q += alphas[i]*t_digits[i]
	end
	for i in 1:n
		for j in 1:n
			q += betas[i,j]*t_digits[i]*t_digits[j]
			q += gammas[i,j]*s_digits[i]*t_digits[j]
		end
	end

	return exp(q)
end

# initialize matrix H
#
# alphas: lagrange multipliers associated to firing rate of individual neurons
# betas: lagrange multipliers associated to instaneous pairwise correlations
# gammas: lagrange multipliers associated to one time step pairwise correlations
function init_H(n::Int64,alpha_min::Float64,alpha_max::Float64,beta_min::Float64,beta_max::Float64,gamma_min::Float64,gamma_max::Float64)
	# inititalize alpha array (random vector)
	alphas = rand(n)
	alphas = float64([alphas[i]*(alpha_max-alpha_min)+alpha_min for i in 1:n])

	# initialize matrix betas (upper triangular random matrix with 0's in the diagonal)
	betas = zeros(Float64,n,n)
	for i in 1:n
		for j in 1:n
			if j>i
				betas[i,j] = rand()*(beta_max-beta_min)+beta_min
			end
		end
	end
	
	# initialize matrix gammas (square random matrix with 0's in the diagonal)
	gammas = zeros(Float64,n,n)
	for i in 1:n
		for j in 1:n
			if j != i
				gammas[i,j] = rand()*(gamma_max-gamma_min)+gamma_min
			end
		end
	end

	# initialize matrix H
	H = zeros(2^n,2^n)

	for x in 1:2^n
		for y in 1:2^n
			H[x,y] = get_H_entry(x-1,y-1,alphas,betas,gammas)
		end
	end

	return alphas,betas,gammas,H
end

function get_principal_eigenvector(H)
	 F = eigfact(H)
	 return F.values[1],F.vectors[:,1]
end

function normalize_H(H,lambda,R)
	N = size(H)[1]
	for x in 1:N
		for y in 1:N
			H[x,y] = (H[x,y]*R[y])/(R[x]*lambda)
		end
	end
end

function get_stationary_distribution(L,R)
	N = length(L)
	dp = dot(L,R)
	return float64([(L[i]*R[i])/dp for i in 1:N])
end

function get_entropy(P,p)
	N = size(P)[1]
	Ep = 0.
	for x in 1:N
		for y in 1:N
			nt = p[x]*P[x,y]
			dt = p[y]*P[y,x]
			Ep += (nt-dt)*log(nt/dt)
		end
	end
	return Ep/2
end

# load data from a text file
#
# time<TAB>neuron_id
function load_data(filename::String,bin_length::Float64)
	f = open(filename, "r")
	lines = readlines(f)
	close(f)
	# nid -> array of firing times
	Dt = Dict{Int64,Array{Float64,1}}()
	# nid -> array of bids
	Dn = Dict{Int64,Array{Int64,1}}()
	# bid -> array of nids
	Db = Dict{Int64,Array{Int64,1}}()
	for l in lines
		ts,ns = split(l,'\t')
		t = float64(ts)
		n = int64(ns)
		bid = int64(floor(t/bin_length)+1)
		# @debug("$bid : $n")
		if haskey(Dt,n)
			push!(Dn[n],t)
		else
			Dt[n] = [t]
		end
		if haskey(Dn,n)
			push!(Dn[n],bid)
		else
			Dn[n] = [bid]
		end
		if haskey(Db,bid)
			push!(Db[bid],n)
		else
			Db[bid] = [n]
		end
	end
	return Dn,Db,Dt
end

# load data from a text file
# 
# initial format
# n1<TAB>n2 ... <TAB>nk<TAB>t11<TAB>t21<TAB><TAB>t41 ... <TAB>tk1<TAB>t12 ...
#
# awk code to be used before: (split records on different lines)
#BEGIN {
#        FS="\t";
#	ORS="\n";
#	OFS=",";
#}
#{
#	for(i=1;i<NF;i++) printf "%s",$i (i%151==0?ORS:OFS)
#}
#END{
#}
#
# awks permits to create a new text file
# n1<TAB>n2 ... <TAB>nk
# t11<TAB>t21<TAB><TAB>t41 ... <TAB>tk1
# t12 ...
#
function load_data2(filename::String,bin_length::Float64)
	f = open(filename, "r")
	lines = readlines(f)
	close(f)
	# nid -> array of firing times
	Dt = Dict{Int64,Array{Float64,1}}()
	# nid -> array of bids
	Dn = Dict{Int64,Array{Int64,1}}()
	# bid -> array of nids
	Db = Dict{Int64,Array{Int64,1}}()
	passed = false
	for l in lines
		# first line of the file: list of neuron ids	
		if passed
			fields = split(l,'\,')
			n = 1
			for f in fields
				# f != " "
				f = strip(f)
				if length(f) > 0
					t = float64(f)
					bid = int64(floor(t/bin_length)+1)

					if haskey(Dt,n)
						push!(Dt[n],t)
					else
						Dt[n] = [t]
					end
					if haskey(Dn,n)
						push!(Dn[n],bid)
					else
						Dn[n] = [bid]
					end
					if haskey(Db,bid)
						push!(Db[bid],n)
					else
						Db[bid] = [n]
					end
				end
				n += 1
			end
		end
		passed = true
	end
	return Dn,Db,Dt
end

# export data in CSV
# one line corresponds to the firing times of a given neuron
function export_data(filename::String,Dt::Dict{Int64,Array{Float64,1}})
	f = open(filename, "w")
	for k in sort([n for n in keys(Dt)])
		fields = sort(Dt[k])
		write(f,string(join(fields,','),'\n'))
	end
	close(f)
end

# get number of firings for a given neuron
function get_nn_firings(nid::Int64, Dt::Dict{Int64,Array{Float64,1}})
	return length(Dt[nid])
end

#
#function get_firing_profile(nid1::Int64, nid2::Int64, n_steps::Int64)
#end

function plot_ebp(filename::String,min_size::Float64,max_size::Float64,step::Float64)
	bin_size = min_size
	X = Float64[]
	Y = Float64[]
	while bin_size <= max_size
		Dn, Db = load_data(filename,bin_size)
		mDb = maximum(keys(Db))
		p = (mDb - length(values(Db)))/length(values(Db))
		push!(X,bin_size)
		push!(Y,p)
		bin_size += step
	end
	plot_scatter_data(X,Y, "scatter", "lines+markers", "zorro")
end

