#
# LNNA: Living Neural Network Analyzer 
# Copyright (C) 2015  Jimmy Dubuisson <jimmy.dubuisson@gmail.com>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#

using Plotly

include("random_matrix.jl")

# option number
o = ARGS[1]

if o == "1"
	# dimension, alpha_min, alpha_max, beta_min, beta_max, gamma_min, gamma_max
	#alphas,betas,gammas,H = init_H(2, 5.0,8.0, -1.0, 2.0, 4.0, 8.0)
	alphas,betas,gammas,H = init_H(2, -3.0,-1.0, -0.2,0.2, -0.2, 0.2)

	println("--- ALPHAS ---")
	println(alphas)
	println("--- BETAS ---")
	println(betas)
	println("--- GAMMAS ---")
	println(gammas)
	println("--- H ---")
	println(H)

	lambda,R = get_principal_eigenvector(H)
	lambda,L = get_principal_eigenvector(H')

	normalize_H(H,lambda,R)
	println("--- norm. H ---")
	println(H)

	p = get_stationary_distribution(L,R)
	println("--- stationary dist. ---")
	println(p)

	Ep = get_entropy(H,p)
	println("--- entropy ---")
	println(Ep)
elseif o == "2"
	n = 2
	alpha_min = -3.0
	alpha_max = -1.0
	beta_min = -0.2
	beta_max = 0.2
	gamma_min = -0.2
	gamma_max = 0.2
	m = 100

	entropies = Float64[]
	for i in 1:m
		alphas,betas,gammas,H = init_H(n, alpha_min,alpha_max, beta_min,beta_max, gamma_min,gamma_max)
		lambda,R = get_principal_eigenvector(H)
		lambda,L = get_principal_eigenvector(H')
		normalize_H(H,lambda,R)
		p = get_stationary_distribution(L,R)
		Ep = get_entropy(H,p)
		push!(entropies,Ep)
	end

	println(entropies)
	println("min: ", minimum(entropies))
	println("max: ", maximum(entropies))
	println("mean: ", mean(entropies))
	println("var: ", var(entropies))
elseif o == "3"
	Dn,Db,Dt = load_data(ARGS[2],20.)

	println("# bins:", length(keys(Db)))
	println("# firing neurons:", length(keys(Dn)))
elseif o == "4"
	Dn,Db,Dt = load_data2(ARGS[2],20.)

	println("# bins:", length(keys(Db)))
	println("# firing neurons:", length(keys(Dn)))

	export_data("test.txt", Dt)
elseif o == "5"
	filename = ARGS[2]
	Dn,Db,Dt = load_data2(filename,0.02)

	#println("# bins:", length(keys(Db)))
	nn = length(keys(Dt))
	println("# firing neurons: $nn")
	
	bin_length = 0.02
	xbl = 4
	ybl = 1
	matrix_size = 151

	TE = generate_te_matrix(Dt, bin_length, xbl, ybl, matrix_size)

	println("mean(TE): ", mean(TE))
	println("var(TE): ", var(TE))
	println("maximum(TE): ", maximum(TE))
	println("minimum(TE): ", minimum(TE))
	
	open("TE_" * replace(filename, ".txt", "") * "_$bin_length-$xbl-$ybl.jld", "w") do file
		serialize(file, TE)
	end
elseif o == "6"
	filename = ARGS[2]
	TE = open(filename, "r") do file
		deserialize(file)
	end

	println("# NNT(TE), % NNZ(TE): ", countnz(TE), " ", countnz(TE)/length(TE))
	
	#Plotly.signin("xxxx", "xxxx")

	Y = sort(vec(reshape(TE,1,length(TE))))
	X = [i for i in 1:length(Y)]

	# plot matrix values
	trace = [
	  [
	  "x" => X,
	  "y" => Y,
	  "type" => "scatter"
	  ]
	]

	layout = [
	  "xaxis" => [
	      "type" => "log",
	          "autorange" => true
		    ],
	      "yaxis" => [
		  "type" => "log",
		  "autorange" => true
		]
	]
	
	data = [trace]
	#response = Plotly.plot(data, ["layout" => layout, "filename" => replace(filename, ".jld", "_values"), "fileopt" => "overwrite"])
	response = Plotly.plot(data, ["filename" => replace(filename, ".jld", "_values"), "fileopt" => "overwrite"])
	plot_url = response["url"]

	# plot matrix heatmap
	data = [
	  [
	      "z" => TE,
	      "type" => "heatmap"
		]
	]
	response = Plotly.plot(data, ["filename" => replace(filename, ".jld", "_matrix"), "fileopt" => "overwrite"])
	plot_url = response["url"]
elseif o == "7"
	filename = ARGS[2]
	TE = open(filename, "r") do file
		deserialize(file)
	end

	gamma = 0.02
	export_2_graphml(replace(filename,".jld", "-$gamma.graphml"), TE, gamma)
elseif o == "8"
	fn_template = ARGS[2]
	@info("template: $fn_template")
	gamma = 0.2
	D = Dict{Int64,Array{Float64,1}}()

	for i in 1:6
		fn = replace(fn_template,"*","$i")
		@info("deserializing file $i: $fn")
		TE = open(fn, "r") do file
			deserialize(file)
		end

		A = get_binary_adjacency_matrix(TE, gamma)
		P = normalize_rows(A)
		PR = my_pagerank(P)
		@info("Max PR: ", maximum(PR))
		@info("Min PR: ", minimum(PR))
		@info("Var PR: ", var(PR))
		D[i] = PR
	end

	MV = hcat(D[1], D[2], D[3], D[4], D[5], D[6])

	# compute mean value of each row
	means = [mean(MV[i,:]) for i in 1:size(MV,1)]
	vars = [var(MV[i,:]) for i in 1:size(MV,1)]
	@info("---")
	#smeans = sort(means, rev=true)
	spmeans = sortperm(means, rev=true)
	spvars = sortperm(vars, rev=true)
	@info("Mean of means PR  : ", mean(means))
	@info("Max of means PR   : ", maximum(means))
	@info("Min of means PR   : ", minimum(means))
	@info("Mean of vars  PR  : ", mean(vars))
	@info("Max of vars PR    : ", maximum(vars))
	@info("Min of vars PR    : ", minimum(vars))
	@info("---")
	@info("max means PR (ids): ", spmeans[1:20])
	@info(" max vars PR (ids): ", spvars[1:20])
	@info("---")
	@info("min means PR (ids): ", spmeans[end-19:end])
	@info(" min vars PR (ids): ", spvars[end-19:end])
	
	open("PR-0.02.jld", "w") do file
		serialize(file, D)
	end
end
