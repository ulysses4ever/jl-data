using XGBoost

# load file from text file, also binary buffer generated by xgboost

dtrain = DMatrix("../data/agaricus.txt.train")
dtest = DMatrix("../data/agaricus.txt.test")

param = ["max_depth"=>2, "eta"=>1, "silent"=>1, "objective"=>"binary:logistic"]
num_round = 2
nfold = 5

print ("running cross validation\n")
nfold_cv(param, dtrain, num_round, nfold, metrics=["error"], seed = 0)

print ("running cross validation, disable standard deviation display\n")

nfold_cv(param, dtrain, num_round, nfold, metrics=["error"], seed = 0, show_stdv = false)

print ("running cross validation, with preprocessing function\n")

function fpreproc(dtrain::DMatrix, dtest::DMatrix, param)
    label = get_info(dtrain, "label")
    ratio = sum(label == 0) / sum(label == 1)
    param["scale_pos_weight"] = ratio
    return (dtrain, dtest, param)
end

nfold_cv(param, dtrain, num_round, nfold, metrics=["auc"],
         seed = 0, show_stdv = false, fpreproc=fpreproc)

print ("running cross validation, with cutomsized loss function\n")


function logregobj(preds::Array{Float32, 1}, dtrain::DMatrix)
        labels = get_info(dtrain, "label")
        preds = 1.0 ./ (1.0 + exp(-preds))
        grad = preds - labels
        hess = preds .* (1.0-preds)
        return (grad, hess)
end

function evalerror(preds::Array{Float32, 1}, dtrain::DMatrix)
    labels = get_info(dtrain, "label")
    # return a pair metric_name, result
    # since preds are margin(before logistic transformation, cutoff at 0)
    tmp = zip(preds, labels)
    cnt = 0
    for itm in tmp
        if convert(Integer, itm[1] > 0.0) != itm[2]
            cnt += 1
        end
    end
    return ("self-error", float(cnt / convert(Real, size(labels)[1])))
end

param = ["max_depth"=>2, "eta"=>1, "silent"=>1]
nfold_cv(param, dtrain, num_round, nfold, metrics=[],
         seed = 0, obj=logregobj, feval=evalerror)
