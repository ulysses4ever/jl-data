function costFunction(params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda)

  # get the theta parameters from the params vector back into matricies
  Theta1 = reshape(params[1:hidden_layer_size * (input_layer_size + 1)],
                   hidden_layer_size, (input_layer_size + 1))
  Theta2 = reshape(params[1 + (hidden_layer_size * (input_layer_size + 1)):end],
                   num_labels, (hidden_layer_size + 1))

  Theta1_no_bias = Theta1[:, 2:end]
  Theta2_no_bias = Theta2[:, 2:end]

  m = size(X, 1)

  # setup return values
  J = 0.0
  Theta1_grad = zeros(size(Theta1))
  Theta2_grad = zeros(size(Theta2))

  # ---- begin: calucate cost
  # --> perform feedforward
  a_1 = [ones(m, 1) X]

  # get values for layer 2
  z_2 = a_1 * Theta1'
  a_2 = sigmoid(z_2)
  a_2 = [ones(m, 1) a_2]

  # get values for layer 3
  z_3 = a_2 * Theta2'
  a_3 = sigmoid(z_3)

  # --> expand labels to binary forms
  binary_labels = eye(num_labels)
  all_binary_y = binary_labels[y[:], :] # the y[:] converts the 1xnum_labels matrix to a column vector.

  pos = -all_binary_y .* log(a_3)
  neg = (1 - all_binary_y) .* log(1 - a_3)
  all_cost = pos - neg

  # get the sum of all costs per label
  sum_label_costs = sum(all_cost)

  # get sum of the sum of all labels
  total_cost = sum(sum_label_costs)

  # complete the last step of the cost function
  J = total_cost/m

  # calculate regularization term
  Theta1_cost_reg = sum(sum(Theta1_no_bias.^2))
  Theta2_cost_reg = sum(sum(Theta2_no_bias.^2))

  J += lambda / (2 * m) * (Theta1_cost_reg + Theta2_cost_reg)

  return J
end

