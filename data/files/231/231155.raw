function generate_reads(;N=100,W=21,L=100,Cprob=[0.3, 0.7],targ_dist=NaN)
	# Generate synthetic data of overlapping reads
    # -----------------------------
    # N = number of reads
    # W = methylation sites per read
    # L = number of methylation-eligible sites
    # Cprob = array listing the proportions of cell types
    # alpha/beta = parameters for beta distribution (prior)
    A = fill(NaN,(N,L))
    c = zeros(Int,N)
    nC = length(Cprob) # number of cell types
    cumC = cumsum(Cprob) - Cprob[1]

    if isnan(targ_dist)
        P = rand((nC,L)) # methylation probabilities
    else
        assert(nC == 2) # only implemented for two clusters
        P = generate_P(N,targ_dist)
    end

    if floor(W/2) == W/2
    	W += 1 # make sure W is odd
    end

    for i = 1:N
    	m = rand(1:L) # middle point of read
    	c[i] = find((i/N) .> cumC)[end] # current cluster
    	s1 = maximum([1,m-floor(W/2)])
    	s2 = minimum([L,m+floor(W/2)])

    	for w = s1:s2
    		if rand(Bernoulli(P[c[i],w])) == 1
    			A[i,w] = 1.0
    		else
    			A[i,w] = -1.0
    		end
    	end
    end

    A,c = sort_reads(A,c)
    obs = find_observations(A)
    return A,P,c,obs
end

function find_observations(A)
    # Return list of indices of non-Nan elements in A
    # -----------------------------
    # A = N x L matrix of reads (with missing entries)
    # returns 
    m,n = size(A)
    obs = (Int64,Int64)[]
    for i = 1:m
        for j = 1:n
            if ~isnan(A[i,j])
                push!(obs,(i,j))
            end
        end
    end
    return obs
end

function sort_reads(A,c::Vector{Int})
    # Sort rows of A based on cluster assignment c
    # -----------------------------
    # A = N x L matrix of reads (with missing entries)
    # c = Vector holding cluster assignments for each row of A
    nc = int(maximum(c)) # number of clusters
    N,W = size(A)
    ind = sortperm(c)
    #A = A[ind,:]
    #c = c[ind]

    # sort by position
    ind = Int64[]
    n = 1
    for ic = 1:nc
        J = Int64[] # array holding first non-NaN element of each row
        while n <= N && c[n] == ic
            push!(J,find(!isnan(A[n,:]))[1])
            n += 1
        end
        ind = vcat(ind,sortperm(J,rev=true)+length(ind))
    end

    return A[ind,:],c[ind]
end

# Compare estimates X and Y, to ground truth ()
function eval_synthetic_results(A,X_in,Y_in,c,P;make_plots=false,save_plots=false,save_prefix="01",variant=:soft)
    # get dimensions
    X,Y = deepcopy(X_in),deepcopy(Y_in)
    k,m = size(X)
    n = size(Y,2)

    # Normalize cols of X to have unit length
    for i = 1:m
        if sum(X[:,i]) > eps()
            X[:,i] /= sum(X[:,i])
        else
            X[:,i] = 0.5*ones(k)
        end
    end

    # compare Y to P across all permutations of rows
    y0 = minimum(Y)
    y1 = maximum(Y)
    Y = (Y-y0)/(y1-y0)  # scale Y to probabilities
    Ydist = Inf
    best_perm = 0
    Yresid = 0
    for perm in permutations(1:k)
        Yresid = vec(Y - P[perm,:])
        yd = sum(abs(Yresid)) # L1 error
        if yd < Ydist
            Ydist = yd
            best_perm = perm
        end
    end
    Ydist /= length(P) # mean L1 error

    # Calculate Xdist
    if variant == :soft
        # X_real are the true posterior proabilities
        X_real = zeros(size(X))
        priors = (1/m) * [sum(c .== ik) for ik=1:k]
        
        for i = 1:m
            # Restrict computations to range of the read
            ind = find(!isnan(A[i,:]))

            # Compute likelihoods for each cell type
            lkhs = ones(k)
            for kk = 1:k
                for j = ind
                    assert(!isnan(A[i,j]))
                    #lkhs[kk] += (A[i,j]==1.0) ? log(P[kk,j]) : log(1-P[kk,j])
                    lkhs[kk] *= (A[i,j]==1.0) ? P[kk,j] : 1-P[kk,j]
                    #lkhs[kk] += A[i,j]*log(Y[kk,j])
                    #lkhs[kk] += (1-A[i,j])*log(1-Y[kk,j])
                end
            end

            # normalize posterior probabilities so they sum to one
            X_real[:,i] = (lkhs.*priors) / sum(lkhs.*priors)
        end
        X_real = X_real[best_perm,:] # use best permutation based on Ydist

        # calculate error
        Xdist = mean(abs(X_real - X))
    elseif variant == :hard
        # X_real is the ground truth
        X_real = zeros(size(X))
        for i = 1:m
            X_real[c[i],i] = 1
        end
        X_real = X_real[best_perm,:] # use best permutation based on Ydist

        # Scale Xdist so that it can be interpretated as the proportion of misclassified reads
        Xdist = sum(abs(X_real - X)) 
        Xdist /= m*2
    else
        error("variant argument incorrect")
    end

    ## Recalculate Ydist based on observed methylation frequencies
    #   --> this is the best case scenario for performance
    if variant == :soft
        Y_real = zeros(size(P))
        for kk = 1:k
            ic = (c.==k)
            Ak = A[ic,:]
            for j = 1:n
                ind = find(!isnan(Ak[:,j]))
                count = sum(Ak[ind,j] .== 1.0)
                total = length(ind)
                Y_real[kk,j] = count / total
            end
        end
    end

    if make_plots
        figure()
        imshow(X,cmap=ColorMap("Greys"),interpolation="none")
        xlabel("Inferred Cluster Assignments")
        yticks([]),xticks([])
        if save_plots; savefig(string("./figs/",save_prefix,"_02.png"),dpi=500); close(); end
        
        figure()
        imshow(X_real,cmap=ColorMap("Greys"),interpolation="none")
        xlabel("true posterior probabilities for reads\n(best soft estimate of X)")
        yticks([]),xticks([])
        if save_plots; savefig(string("./figs/",save_prefix,"_03.png"),dpi=500); close(); end

        # Compare true and inferred methylation probabilities
        figure(), imshow(Y,cmap=ColorMap("Greys"),interpolation="none")
        xlabel("Estimated methylation profiles"), yticks([]), xticks([])
        if save_plots; savefig(string("./figs/",save_prefix,"_04.png"),dpi=500); close(); end

        figure()
        imshow(P,cmap=ColorMap("Greys"),interpolation="none")
        xlabel("Reconstructed methylation profiles"), yticks([]), xticks([])
        if save_plots; savefig(string("./figs/",save_prefix,"_05.png"),dpi=500); close(); end

        figure(figsize=(8,3)),PyPlot.hist(Yresid,50),xlim([-0.5,0.5])
        xlabel("Residuals (for methylation profiles)",fontweight="bold")
        if save_plots; savefig(string("./figs/",save_prefix,"_06.svg")); close(); end
    end

    return Xdist,Ydist,X_real
end

function opt_performance(A,c,p)
    # Find the start and end of each read
    for i = 1:size(A,1)
        ind = find(!isnan(A[i,:]))
        Y[:,ind] # true distributions to choose from
    end
end

function d_kl_bern(p,q)
    ## Kulback-Leibler divergence for two Bernoulli variables with probabilities p and q
    return p*log2(p./q)+(1-p)*log2((1-p)/(1-q))
end

function d_js_bern(p1,p2)
    ## Jenson-Shannon divergence for two Bernoulli variables with probabilities p1 and p2
    m = 0.5*(p1+p2)
    return 0.5*d_kl_bern(p1,m) + 0.5*d_kl_bern(p2,m)
end

function d_js_multivar_bern(x::Vector,y::Vector)
    ## Jenson-Shannon divergence between two multivariate Bernoulli variables
    dist = 0
    for i=1:length(x)
        dist += d_js_bern(x[i],y[i])
    end
    # normalize by the dimension. Result should be on interval [0,1].
    return dist / length(x)
end

function generate_P(N,targ_dist)
    x = rand(N) # first methylation profile
    y = deepcopy(x) # second methylation profile

    # Increase distance until targ_dist is reached
    while d_js_multivar_bern(x,y) < targ_dist
        y[rand(1:N)] = rand()
    end

    return [x';y']
end

