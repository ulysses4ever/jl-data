function generate_reads(;N=100,W=21,L=100,Cprob=[0.3, 0.7],targ_dist=NaN)
	# Generate synthetic data of overlapping reads
    # -----------------------------
    # N = number of reads
    # W = methylation sites per read
    # L = number of methylation-eligible sites
    # Cprob = array listing the proportions of cell types
    # alpha/beta = parameters for beta distribution (prior)
    A = fill(NaN,(N,L))
    c = zeros(Int,N)
    nC = length(Cprob) # number of cell types
    cumC = cumsum(Cprob) - Cprob[1]

    if isnan(targ_dist)
        P = rand((nC,L)) # methylation probabilities
    else
        assert(nC == 2) # only implemented for two clusters
        P = generate_P(N,targ_dist)
    end

    if floor(W/2) == W/2
    	W += 1 # make sure W is odd
    end

    for i = 1:N
    	m = rand(1:L) # middle point of read
    	c[i] = find((i/N) .> cumC)[end] # current cluster
    	s1 = maximum([1,m-floor(W/2)])
    	s2 = minimum([L,m+floor(W/2)])

    	for w = s1:s2
    		if rand(Bernoulli(P[c[i],w])) == 1
    			A[i,w] = 1.0
    		else
    			A[i,w] = -1.0
    		end
    	end
    end

    A,c = sort_reads(A,c)
    obs = find_observations(A)
    return A,P,c,obs
end

function find_observations(A)
    # Return list of indices of non-Nan elements in A
    # -----------------------------
    # A = N x L matrix of reads (with missing entries)
    # returns 
    m,n = size(A)
    obs = (Int64,Int64)[]
    for i = 1:m
        for j = 1:n
            if ~isnan(A[i,j])
                push!(obs,(i,j))
            end
        end
    end
    return obs
end

function sort_reads(A,c::Vector{Int})
    # Sort rows of A based on cluster assignment c
    # -----------------------------
    # A = N x L matrix of reads (with missing entries)
    # c = Vector holding cluster assignments for each row of A
    nc = int(maximum(c)) # number of clusters
    N,W = size(A)
    ind = sortperm(c)
    #A = A[ind,:]
    #c = c[ind]

    # sort by position
    ind = Int64[]
    n = 1
    for ic = 1:nc
        J = Int64[] # array holding first non-NaN element of each row
        while n <= N && c[n] == ic
            push!(J,find(!isnan(A[n,:]))[1])
            n += 1
        end
        ind = vcat(ind,sortperm(J,rev=true)+length(ind))
    end

    return A[ind,:],c[ind]
end

# Compare estimates X and Y, to ground truth ()
function eval_synthetic_results(X_in,Y_in,c,P;make_plots=false,save_plots=false)
    # get dimensions
    X,Y = deepcopy(X_in),deepcopy(Y_in)
    m,k = size(X)
    n = size(Y,2)

    # Normalize rows of X to have unit length
    for i = 1:m
        if sum(X[i,:]) > eps()
            X[i,:] /= sum(X[i,:])
        else
            X[i,:] = 0.5*ones(k)
        end
    end

    # compare Y to P across all permutations of rows
    y0 = minimum(Y)
    y1 = maximum(Y)
    Y = (Y-y0)/(y1-y0)  # scale Y to probabilities
    Ydist = Inf
    best_perm = 0
    Yresid = 0
    for perm in permutations(1:k)
        Yresid = vec(Y - P[perm,:])
        yd = sum(abs(Yresid)) # L1 error
        if yd < Ydist
            Ydist = yd
            best_perm = perm
        end
    end
    Ydist /= length(P) # mean L1 error

    # Construct "true" X matrix
    X_real = zeros(size(X))
    for i = 1:m
        X_real[i,c[i]] = 1
    end
    X_real = X_real[:,best_perm] # use best permutation based on Ydist

    # # compare X to X_real across all permutations of columns
    # Xdist = Inf
    # for perm in permutations(1:k)
    #     # Compute distance for this permutation of X_real
    #     xd = 0
    #     for i = 1:m
    #         xd += sum(abs(X_real[i,perm] - X[i,:]))
    #     end
    #     # Save the smallest distance across permutations
    #     if xd < Xdist
    #         Xdist = xd
    #     end
    # end

    # Scale Xdist so that it can be interpretated as the proportion of misclassified reads
    Xdist = sum(abs(X_real - X)) 
    Xdist /= m*2

    if make_plots
        figure()
        imshow(X',cmap=ColorMap("Greys"),interpolation="none")
        xlabel("Inferred Cluster Assignments")
        yticks([])
        if save_plots; savefig("./figs/01_02.png",dpi=500); close(); end
        
        figure()
        imshow(X_real',cmap=ColorMap("Greys"),interpolation="none")
        xlabel("True Cluster Assignments")
        yticks([])
        if save_plots; savefig("./figs/01_03.png",)dpi=500; close(); end

        # Compare true and inferred methylation probabilities
        figure(), imshow(Y,cmap=ColorMap("Greys"),interpolation="none")
        xlabel("Reconstructed methylation profiles"), yticks([])
        if save_plots; savefig("./figs/01_04.png",dpi=500); close(); end

        figure()
        imshow(P,cmap=ColorMap("Greys"),interpolation="none")
        xlabel("True methylation profiles"), yticks([])
        if save_plots; savefig("./figs/01_05.png",dpi=500); close(); end

        figure(figsize=(8,3)),PyPlot.hist(Yresid,50)
        xlabel("Residuals (for methylation profiles)",fontweight="bold")
        if save_plots; savefig("./figs/01_06.svg"); close(); end
    end

    return Xdist,Ydist
end


function d_kl_bern(p,q)
    ## Kulback-Leibler divergence for two Bernoulli variables with probabilities p and q
    return p*log2(p./q)+(1-p)*log2((1-p)/(1-q))
end

function d_js_bern(p1,p2)
    ## Jenson-Shannon divergence for two Bernoulli variables with probabilities p1 and p2
    m = 0.5*(p1+p2)
    return 0.5*d_kl_bern(p1,m) + 0.5*d_kl_bern(p2,m)
end

function d_js_multivar_bern(x::Vector,y::Vector)
    ## Jenson-Shannon divergence between two multivariate Bernoulli variables
    dist = 0
    for i=1:length(x)/2
        dist += d_js_bern(x[i],y[i])
    end
    return dist
end

function generate_P(N,targ_dist)
    x = rand(100) # first methylation profile
    y = deepcopy(x) # second methylation profile

    # Increase distance until targ_dist is reached
    while d_js_multivar_bern(x,y) < targ_dist
        y[rand(1:100)] = rand()
    end

    return [x';y']
end

