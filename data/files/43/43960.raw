#=
 = Create FFT power spectral coefficients (one-sided) at locations where
 = analyses provide good coverage of the 2001-2007 period and store a weighted
 = average of these spectra - RD October 2015
 =#

using My #, NFFT
const MISS             = -9999.0                        # generic missing value
const DAYS             = 3745                           # number of days in full timeseries
const TIMES            = 2556                           # number of days in during 2001-2007 (and number of spectral coefficients)

if size(ARGS) != (2,)
  print("\nUsage: jjj $(basename(@__FILE__)) all.flux.locate.min2000 cfsr\n\n")
  exit(1)
end

spectra  = zeros(Float64, div(TIMES, 2) + 1)                                  # allocate space for the average spectrum
torus(x) =              (x - 459) / TIMES - 0.5                               # map daily index to the NFFT torus [-0.5,0.5)
#bartl(x) = x < 1736.5 ? (x - 459) / 1277.5 : (3014 - x) / 1277.5              # map daily index to Bartlett triangular weights
bartl(x) = 1.0

totsum = 0.0
csv = readcsv(ARGS[1])                                                        # for each location with a good
(locs,) = size(csv)                                                           # timeseries, read the flux data
for a = 1:locs
  if csv[a,3] > 0
    tmpa = @sprintf("%9.3f.%9.3f", csv[a,1], csv[a,2])
    tmpb = replace(tmpa, " ", ".")
    tmpc = "$(ARGS[2])/$(ARGS[2]).$tmpb"
    tmpd = "$(ARGS[2])/$(ARGS[2]).$tmpb.fft"
    tmpe = "$(ARGS[2])/$(ARGS[2]).$tmpb.fftest"

    data = Array(Float64, 0)
    datb = Array(Float64, 0)
    datc = Array(Float64, 0)

    fpa = My.ouvre(tmpc, "r", false) ; lines = readlines(fpa) ; close(fpa)    # read  date    shf       lhf
    for line in lines                                                         # 1999102312 62.820 -9999.000
      vals = float(split(line))
      push!(data, vals[2])
    end
    (nums,) = size(data)
    if nums != DAYS  write(STDERR, "ERROR : read $nums (!= $DAYS) lines from $tmpc\n") ; exit(-1)  end

    push!(datb, torus(459))                                                   # define the NFFT sampled data with
    push!(datc, bartl(459) * 0.0)                                             # valid (zero-amplitude) endpoints
    for b = 460:3013                                                          # at 2001-01-01 and 2007-12-31
      if -333 < data[b] < 3333
        push!(datb, torus(b))
        push!(datc, bartl(b) * data[b])
      end
    end
    push!(datb, torus(3014))
    push!(datc, bartl(3014) * 0.0)
    nums = length(datb)

    fpa = My.ouvre(tmpd, "w", false)
    for b = 1:nums
      tmpa = @sprintf("%15.8f %15.8f\n", datb[b], datc[b])
      write(fpa, tmpa)
    end
    close(fpa)

    run(`diag.heat.flux.timeseries.nfft $tmpd`)                               # compute and sum each spectra, weighted
    fpa = My.ouvre(tmpe, "r", false) ; lines = readlines(fpa) ; close(fpa)    # by csv[a][3] (and then clean up also)
    for (b, line) in enumerate(lines)
      vals = float(split(line))
      spectra[b] += vals[2] * csv[a,3]
    end
exit(0)
    rm(tmpd) ; rm(tmpe)
    totsum += csv[a,3]
  end
end

tmpa = @sprintf("spectrum.%s.%s", ARGS[1], ARGS[2])                           # store the weighted average spectrum
fpa = My.ouvre(tmpa, "w")
for a = 1:div(TIMES, 2) + 1
  tmpa = @sprintf("%15.8f %15.8f\n", (a - 1) / TIMES, spectra[a] / totsum)
  write(fpa, tmpa)
end
close(fpa)
exit(0)


#=
plan = NFFTPlan(datb, nums)
spec = nfft(plan, datc)

mask = [in((x, y), buoy) for x=lons, y=lats]                                  # locs[1440,720] = ( 179.75, 89.75)
varc = locs[mask .== true] ; (varn,) = size(varc)
tmp = @sprintf("%s %9.3f %9.3f\n", date[1:10], MISS, sublhf[a])
write(fpn, tmp)
close(fpn)
=#
