using MathProg

require("nlp.jl")

function clnlbeam()
    ni    = 500
    alpha = 350
    h     = 1/ni
    halfH = h/2

    m = Model("min")

    @defVar(m, -1 <= t[1:(ni+1)] <= 1)
    @defVar(m, -0.05 <= x[1:(ni+1)] <= 0.05)
    @defVar(m, u[1:(ni+1)])

    cons = Array(Expr,0)
    # cons1
    for i in 1:ni
        push!(cons, @nlexpr x[i+1] - x[i] - halfH*(sin(t[i+1])+sin(t[i])))
    end
    # cons2
    for i in 1:ni
        push!(cons, @nlexpr t[i+1] - t[i] - halfH*u[i+1] - halfH*u[i])
    end

    return m,cons

end

function cont5_1()
    n = 200
    m = n 
    T = 1
    dt = T/m
    l = atan(1)
    dx = l/n
    h2 = dx^2
    dtinv = 1/dt

    model = Model("min")

    # add 1 to ampl indices for y
    @defVar(model, -10 <= y[1:(m+1),1:(n+1)] <= 10)
    @defVar(model, 0 <= u[1:m] <= 1)

    cons = Array(Expr,0)
    # pde
    for i in 0:(m-1), j in 1:(n-1)
        push!(cons, @nlexpr dtinv*(y[i+2,j+1] - y[i+1,j+1]) - 
            (0.5h2)*(y[i+1,j] - 2y[i+1,j+1] + y[i+1,j+2] + y[i+2,j] - 2y[i+2,j+1] + y[i+2,j+2]))
    end

    # bc1
    for i in 1:m
        push!(cons, @nlexpr (2dtinv)*(y[i+1,3] - 4y[i+1,2] + 3y[i+1,1]))
    end
    
    # bc2
    for i in 1:m
        push!(cons, @nlexpr((2dtinv)*(y[i+1,n-1] - 4y[i+1,n] + 3y[i+1,n+1]) -
         y[i+1,n+1] - u[i] - y[i,n] + y[i+1,n+1]*(y[i+1,n+1]^2)^(1.5)) )
        # use y*(y^2)^(3/2) instead of y*abs(y)^3 
    end

    return model,cons
end


instances = [:clnlbeam, :cont5_1]
#instances = [:cont5_1]
#instances = [:clnlbeam]


function dobench()
    N = 99

    modeltime = Float64[]
    prepjacobian = Float64[]
    firsteval = Float64[]
    nextN = Float64[]
    for i in instances
        f = eval(i)

        t = time()
        m,cons = f()
        push!(modeltime,time()-t)

        t = time()
        elts, colval, rowstarts = sparseJacobian(m,cons)
        push!(prepjacobian,time()-t)

        xval = ones(m.numCols)
        
        t = time()
        # preallocate output
        nzval = Array(Float64,length(colval))
        elts(xval,nzval)
        push!(firsteval,time()-t)

        t = time()
        for k in 1:N
            elts(xval,nzval)
        end
        push!(nextN,time()-t)
        
        println("### $(string(i)) $(modeltime[end]) $(prepjacobian[end]) $(firsteval[end]) $(nextN[end])")

        println("## $(string(i)) Jacobian norm: $(norm(nzval,2)) (nnz = $(length(nzval)))")
    end
end

function dobenchOld()
    N = 100

    modeltime = Float64[]
    prepjacobian = Float64[]
    firsteval = Float64[]
    nextN = Float64[]
    for i in instances
        f = eval(i)

        t = time()
        m,cons = f()
        push!(modeltime,time()-t)

        t = time()
        elts, colval, rowstarts = @time sparseJacobianOld(m,cons)
        push!(prepjacobian,time()-t)

        xval = ones(m.numCols)
        
        t = time()
        nzval = elts(xval)
        push!(firsteval,time()-t)

        t = time()
        for k in 1:N
            nzval = elts(xval)
        end
        push!(nextN,time()-t)
        
        println("### $(string(i)) $(modeltime[end]) $(prepjacobian[end]) $(firsteval[end]) $(nextN[end])")
    end
end

dobench()
        




