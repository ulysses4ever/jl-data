module AdaBoosts

using Distributions

importall Classifiers

export predict,fit,AdaBoostConfig,AdaBoost,loss

type AdaBoostConfig <: ClassifierConfig
  # fit_function::Function
  # predict_function::Function
  weak_config::ClassifierConfig
  max_weak_classifiers::Int
  subsample_cumulative_distribution::Float64
  min_samples::Float64
end

type AdaBoost <: Classifier
    models::Vector{Classifier}
    weights::Vector{Float64}
    config::AdaBoostConfig
end

function subsample(probabilities::Vector{Float64},subsample_cumulative_distribution::Float64)
  c=Categorical(probabilities)
  a = sampler(c)
  sampled=0
  n=length(probabilities)
  selected=falses(n)
  while (sampled<subsample_cumulative_distribution)
    index=rand(a)
    while (selected[index])
      index=rand(a)
    end
    selected[index]=true
    sampled+=probabilities[index]
  end

  return selected
end

function same(x::Vector)
  n=length(x)
  if (n==0)
    return true
  end
  i=2
  while ((i<=n) && (x[i]==x[i-1] ))
    i+=1
  end
  return i>n
end

function fit(c::AdaBoostConfig,x,y)
models=Classifier[]
weights=Float64[]
n=length(x)
probabilities=ones(Float64,n)/n
i=1
average_error=1
while i<=c.max_weak_classifiers && average_error>0.001
    if (!isprobvec(probabilities))
      break
    end
    indices=subsample(probabilities,c.subsample_cumulative_distribution)
    samples=count(identity,indices)
    #println("$samples samples")
    #println("Min max prob: $(minimum(probabilities)) $(maximum(probabilities))")
    if (samples<c.min_samples)
      break
    end
    x_sub=x[indices]
    y_sub=y[indices]
    if same(y_sub)
      break
    end

    model=fit(c.weak_config,x_sub,y_sub)
    predicted=predict(model,x)
    errors=predicted.!=y
    average_error=mean(errors)
    #println("Weak model $i error: $average_error")
    weight=0.5*log((1-average_error)/average_error)
    probabilities=probabilities.*exp(-weight.*predicted.*y)
    probabilities=probabilities./sum(probabilities)
    push!(models,model)
    push!(weights,weight)
    i=i+1
end

return AdaBoost(models,weights,c)
end

loss(m::AdaBoost,predicted::Vector{Float64},y::Vector{Int}) = sign(predicted).!=y


function predict_one(m::AdaBoost,x)
  sign(dot(map(weak_model->predict(weak_model,x),m.models),m.weights))
end
function predict(m::AdaBoost,xs)
  map(x -> predict_one(m,x),xs)
end

end
