
type Parameters
	train_path::ASCIIString
	test_path::ASCIIString
	dim::Int
	k::Int
	p::Int
	l::Float64
	L::Float64
	n0::Int
	train_size::Int
	dispatch_frac::Float64
	chunk_size::Int
	seed::Int
	output::ASCIIString
	machine_file::ASCIIString
	num_workers::Int
	# SGD parameters
	TYPE::Float64
	local_features_size::Int
	lambda_l1_local::Float64
	lambda_l1_global::Float64
	lambda_l2::Float64
	loss_type::Int
	alpha_l::Float64
	beta_l::Float64
	alpha_g::Float64
	beta_g::Float64
	t_factor::Float64
	num_passes::Int
	mb_size::Int
end

function Parameters(ARGS)
	aps = ArgParseSettings()
	@add_arg_table aps begin
		"--base_directory", "-b"
		help = "Path to parent of train.txt and test.txt"
		required = true
		"--dimension", "-d"
		help = "Dimensionality of hashed data"
		arg_type = Int
		required = true
		"--clusters", "-k"
		help = "Number of clusters"
		arg_type = Int
		required = true
		"--replication", "-p"
		help = "Replication factor"
		arg_type=Int
		default = 1
		"--n0", "-r"
		help = "Leaf-node size in random partition tree"
		arg_type = Int
		default=50
		"--train_size", "-n"
		help = "Number of training examples"
		arg_type = Int
		required = true
		"--dispatch_size", "-m"
		help = "Number of samples to use for dispatch and clustering"
		arg_type = Int
		required = true
		"--chunk_size", "-c"
		help = "Number of samples to be processed at a time."
		arg_type = Int
		default = 2000
		"--seed"
		help = "Random seed"
		arg_type = Int
		default = 0
		"--output"
		help = "Directory to store the dispatched data on the workers"
		arg_type = ASCIIString
		default = "./"
		"--workers"
		help = "Path to a machine file in the julia format"
		arg_type = ASCIIString
		default = ""
		"--num_workers"
		help = "Number of workers to use"
		arg_type = Int
		default = 1
		"--dataset_name"
		help = "Name of dataset."
		arg_type = ASCIIString
		required = true
		"--communication_type", "-t"
		help = "Communication type"
		arg_type = Float64
		default = 2.0
		"--loss_type"
		help = "Type of loss"
		arg_type = ASCIIString
		default = "3"
		"--local_features_size"
		help = "Number of features to use locally"
		arg_type = Int
		default = 10007
		"--num_passes"
		help = "Number of passes through the data"
		arg_type = Int
		default = 10
		"--mb_size"
		help = "Size of minibatch"
		arg_type = Int
		default = 10000
	end
	parsed_args = parse_args(ARGS, aps)

	base_directory = parsed_args["base_directory"]
	train_path = joinpath(base_directory, "train.txt")
	test_path = joinpath(base_directory, "test.txt")
	dim = parsed_args["dimension"]
	k = parsed_args["clusters"]
	p = parsed_args["replication"]
	l = p/2/k
	L = p*2/k
	n0 = parsed_args["n0"]
	train_size = parsed_args["train_size"]
	dispatch_frac = parsed_args["dispatch_size"] / train_size
	chunk_size = parsed_args["chunk_size"]
	seed = parsed_args["seed"]
	output = parsed_args["output"]
	machine_file = parsed_args["workers"]
	num_workers = parsed_args["num_workers"]
	TYPE = parsed_args["communication_type"]
	local_features_size = parsed_args["local_features_size"]
	num_passes = parsed_args["num_passes"]

	loss_dict = Dict("logistic" => 1, "logloss" => 1, "1" => 1, "hinge" => 2, "2" => 2, "l1svm" => 2, "svm" => 2, "sqhinge" => 3, "l2svm" => 3, "3" => 3)
	loss_type = loss_dict[parsed_args["loss_type"]]
	mb_size = parsed_args["mb_size"]

	if parsed_args["dataset_name"] == "ctra"
		if TYPE == 2.0
			lambda_l1_local = 1e-2
			lambda_l1_global = 1e-3
			lambda_l2 = 1e-4
			alpha_l = 0.12
			beta_l = 1.0
			alpha_g = 0.12
			beta_g = 1.0
			t_factor = 5.0
		elseif TYPE == 1.0
			lambda_l1_local = 1e-2
			lambda_l1_global = 1e-3
			lambda_l2 = 1e-4
			alpha_l = 0.2
			beta_l = 1.0
			alpha_g = (local_features_size < 100) ? 0.2 : 1.0
			beta_g = 1.0
			t_factor = 5.0
		end
	elseif parsed_args["dataset_name"] == "criteo"
		if TYPE == 2.0
			lambda_l1_local = 5e-4
			lambda_l1_global = 5e-5
			lambda_l2 = 1e-4
			alpha_l = 0.8
			beta_l = 1.0
			alpha_g = 0.8
			beta_g = 1.0
			t_factor = 1.0
		elseif TYPE == 1.0
			lambda_l1_local = 5e-4
			lambda_l1_global = 5e-5
			lambda_l2 = 1e-4
			alpha_l = 0.8
			beta_l = 1.0
			alpha_g = 600
			beta_g = 1.0
			t_factor = 1.0
		end
	else
		error("Dataset unknown.")
	end

	return Parameters(train_path, test_path, dim, k, p, l, L, n0, train_size,
	dispatch_frac, chunk_size, seed, output,
	machine_file, num_workers, TYPE, local_features_size,
	lambda_l1_local, lambda_l1_global, lambda_l2, loss_type,
	alpha_l, beta_l, alpha_g, beta_g, t_factor, num_passes, mb_size)
end
